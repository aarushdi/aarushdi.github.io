<!DOCTYPE html>
<html>
<!-- *********************************************************** -->
<head>
  <meta charset="utf-8">
  <title>.: Ahmad A. Rushdi | Projects :.</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="shortcut icon" href="assets/favicon.ico">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Almarai:wght@300;700&family=Cairo:wght@600;700;800&family=Nunito:wght@300;700&display=swap" rel="stylesheet">

  <!-- Modern external stylesheet -->
  <link rel="stylesheet" href="css/styles.css">
  <!-- *********************************************************** -->
</head>

<!-- *********************************************************** -->

<body>
  <div class="container">
      <!-- *********************************************************** -->
    <div class="left-column">
      <h1> أحْمَد رُشْدِي </h1>
      <img id="main-profile-pic"; width="150px"; src="assets/Ahmad_web_bw.png" alt="Ahmad Rushdi" class="rounded-corners">
      <h2>Ahmad A. Rushdi</h2>
      <p style="margin: 0">Research Scientist</p>
      <p style="margin: 0">Director, Industry Research</p>
      <p style="margin: 0"><a href="https://hai.stanford.edu/">Institute for Human-Centered AI</a></p>
      <p style="margin: 0"><a href="https://www.stanford.edu/">Stanford University</a></p>
      <p> <a href = "mailto: rushdi@stanford.edu"><i class="fa fa-envelope"></i></a>
        <a href = "https://scholar.google.com/citations?user=9F-0uvIAAAAJ&hl=en"><i class="fa fa-google"></i></a>
        <a href = "https://www.linkedin.com/in/ahmadrushdi/"><i class="fa fa-linkedin"></i></a>
        <a href = "https://github.com/aarushdi"><i class="fa fa-github"></i></a>
      </p>
      <a href="index.html" class="nav-button">Home</a>
      <a href="publications.html" class="nav-button">Publications</a>
      <a href="talks.html" class="nav-button">Talks</a>
      <a href="projects.html" class="nav-button">Projects</a>
    </div>
    <!-- *********************************************************** -->
    <div class="right-column">
        
        <h2>Selected Projects</h2>
        
        <p><h4>For projects with no linked papers, further details could be made available upon request.</h4></p>
        
        <hr>
        <!-- *********************************************************** -->

        <p> <b>High-d sampling and visualization in scientific computing</b>: A library of high-dimensional test functions for optimization, uncertainty quantification, and numerical integration problems.</p>

        <div class="flex-container">
          <video class="video" autoplay loop muted playsinline> <source src="viz/library/vid-bukin.mp4" type="video/mp4">Your browser does not support the video tag.</video>
          <video class="video" autoplay loop muted playsinline> <source src="viz/library/vid-cone.mp4" type="video/mp4">Your browser does not support the video tag.</video>
          <video class="video" autoplay loop muted playsinline> <source src="viz/library/vid-cross.mp4" type="video/mp4">Your browser does not support the video tag.</video>
          <video class="video" autoplay loop muted playsinline> <source src="viz/library/vid-rosenbrock.mp4" type="video/mp4">Your browser does not support the video tag.</video>
          <video class="video" autoplay loop muted playsinline> <source src="viz/library/vid-franke.mp4" type="video/mp4">Your browser does not support the video tag.</video>
          <video class="video" autoplay loop muted playsinline> <source src="viz/library/vid-egg-holder.mp4" type="video/mp4">Your browser does not support the video tag.</video>
          <video class="video" autoplay loop muted playsinline> <source src="viz/library/vid-herbie.mp4" type="video/mp4">Your browser does not support the video tag.</video>
          <video class="video" autoplay loop muted playsinline> <source src="viz/library/vid-rastrigin.mp4" type="video/mp4">Your browser does not support the video tag.</video>
          <!-- *****************************************
          <video class="video" autoplay loop muted playsinline> <source src="viz/library/vid-michalewicz.mp4" type="video/mp4">Your browser does not support the video tag.</video>
          <video class="video" autoplay loop muted playsinline> <source src="viz/library/vid-shubert.mp4" type="video/mp4">Your browser does not support the video tag.</video>
          ****************** -->
          
        </div>
        
        <div class="flex-container">
          <img src="viz/library/cnt-bukin.png" alt="" width="150px">
          <img src="viz/library/cnt-cone.png" alt="" width="150px">
          <img src="viz/library/cnt-cross.png" alt="" width="150px">
          <img src="viz/library/cnt-rosenbrock.png" alt="" width="150px">
          <img src="viz/library/cnt-franke.png" alt="" width="150px">
          <img src="viz/library/cnt-egg-holder.png" alt="" width="150px">
          <img src="viz/library/cnt-herbie.png" alt="" width="150px">
          <img src="viz/library/cnt-rastrigin.png" alt="" width="150px">
          <!-- *****************************************************
          <img src="viz/library/cnt-michalewicz.png" alt="" width="150px">
          <img src="viz/library/cnt-shubert.png" alt="" width="150px">
          ****** -->
        </div>
        
        <hr>
        <!-- *********************************************************** -->
        
        <p> <b>Model evaluation and uncertainty quantification for AI/ML</b>: quantifying uncertainty in AI/ML predictive estimates, decomposing it into aleatoric and epistemic components, and consequently guiding active learning.</p>
        
        
        <p> <b>Vision</b>: Quantifying uncertainty in object detection, segmentation, and image generation-captioning workflows.</p>

        <div class="flex-container">

          <figure class="flex-figure-item">
              <img src="viz/UQ/DallE/Dalle3.jpeg" alt="">
            <figcaption>Text-to-image generation using Dall-E 3. Prompt: "A nature reserve showing a giraffe, elephant, zebra, and lion, faceted style. Colorful background." </figcaption>
          </figure>
          <figure class="flex-figure-item">
              <img src="viz/UQ/DallE/Yolo.png" alt="">
                  <figcaption>Object detection using YOLOv3, trained on COCO. class,confidence,bx,by,bw,bh
                      horse,0.23,0.46,0.54,0.06,0.05
                      zebra,0.96,0.31,0.88,0.13,0.15
                      zebra,0.99,0.75,0.83,0.30,0.20
                      zebra,0.97,0.11,0.82,0.14,0.11
                      zebra,0.98,0.07,0.67,0.09,0.06
                      giraffe,0.97,0.30,0.55,0.28,0.50
                  </figcaption>
          </figure>
          
          <figure class="flex-figure-item">
              <img src="viz/UQ/DallE/SAM.png" alt="">
            <figcaption>Image segmentation using Meta's Segment Anything (SAM) </figcaption>
          </figure>
          
          <figure class="flex-figure-item">
              <img src="viz/UQ/DallE/caption2.png" alt="">
            <figcaption>Image captioning using BLIP (via a Huggingface inference API) </figcaption>
          </figure>
        
          
          </div>
        

        <b>Image classification</b>: Accuracy/uncertainty impact of rotation and AWGN addition on NN classifiers, applied to MNIST/CIFAR.
          
          <!-- ** MNIST ** -->
          <div class="flex-container">

            <figure class="flex-figure-item">
              <img src="viz/UQ/MNIST/x_test.png" alt="", width="150">
              <img src="viz/UQ/CIFAR/x_test.png" alt="", width="150">
            </figure>
            
            <video class="video-large" autoplay loop muted playsinline> <source src="viz/UQ/MNIST/rotated_video.mp4" type="video/mp4" >Your browser does not support the video tag.</video>
            <video class="video-large" autoplay loop muted playsinline> <source src="viz/UQ/MNIST/noisy_video.mp4" type="video/mp4" >Your browser does not support the video tag.</video>
            
            </div>
          
          <p> <b>1-d regression</b>: estimating uncertainty bands with deep ensembles, Monte Carlo dropout, and conformal prediction over limited/noisy observations.</p>

          <div class="flex-container">
            
            <!-- ** 1d ** -->
            <figure>
              <img src="viz/UQ/1d/0-samples.png" alt="samples", width="400">
            </figure>
            <video class="video-large" autoplay loop muted playsinline> <source src="viz/UQ/1d/UQ_1d.mp4" type="video/mp4" >Your browser does not support the video tag.</video>
            
            </div>
          
          <b>Time series classification</b>: predicting class and estimating uncertainty with missing/incomplete time series.
            <!-- ** Time Series ** -->
            <div class="flex-container">
                
                <figure>
                    <img src="viz/UQ/timeseries/fungi.png" alt="", width="500">
                </figure>
                
                <figure>
                    <img src="viz/UQ/timeseries/gesture.png" alt="", width="500">
                </figure>
                
                
              </div>
              <hr>
        
        <!-- *********************************************************** -->
        
        <p> <b>Fourier and signal processing methods in biomedical and bioinfromatics applications</b>: for feature extraction (e.g., period-3 in DNA), object localization (e.g., echos in ultrasound), and spectral analysis of high-d sampling techniques using Nd-FFT.</p>

        <div class="flex-container">

          <figure class="flex-figure-item">
            <img src="viz/bio/persistence.png" alt="persistence">
            <figcaption>Persistence spectrum: an interference narrowband signal embedded in a broadband signal </figcaption>
          </figure>
          <figure class="flex-figure-item">
            <img src="viz/bio/period-3.png" alt="period-3">
            <figcaption>ST-DFT spectral analysis for finding the codon bias in DNA [<a href="https://ieeexplore.ieee.org/document/4550567">paper</a>]</figcaption>
          </figure>
          <figure class="flex-figure-item">
            <img src="viz/bio/ultrasound.png" alt="ultrasound">
            <figcaption>Digital notch filtering to detect wideband ultrasound contrast echos in blood </figcaption>
          </figure>
          <figure class="flex-figure-item">
            <img src="viz/bio/0p79_txt_spec.png" alt="Spoke-darts">
            <figcaption>Fourier spectrum analysis of high dimensional sample patterns [<a href="https://dl.acm.org/doi/abs/10.1145/3194657">paper</a>]</figcaption>
          </figure>
          
          </div>
          
          <hr>
          
          <!-- *********************************************************** -->
          
          <p> <b> Voronoi Piecewise Surrogate (VPS) models</b>: Leveraging the properties of Voronoi diagrams and Delaunaey graphs in global surrogate modeling problems for high-dimensional uncertainty quantification and adaptive sampling scenarios with a limited sample budget (e.g., multifidelity/costly/high-stakes numerical simulations).</p>
          
          <div class="flex-container">

              <figure class="flex-figure-item">
                <img src="viz/VPS/VPS_neighbors.png" alt="RSD">
                <figcaption>Finding significant Voronoi neighbors in high dimension [<a href="https://www.sciencedirect.com/science/article/pii/S1877705816333380">paper</a>]</figcaption>
              </figure>
              <figure class="flex-figure-item">
                <img src="viz/VPS/VPS2.png" alt="VPS">
                <figcaption>A global high-d surrogate stitching local patches in Voronoi cells [<a href="https://www.dl.begellhouse.com/journals/52034eb04b657aea,7bd16ae14fe9cbcf,1c04fb773044c729.html">paper</a>]</figcaption>
              </figure>
              <figure class="flex-figure-item">
                <img src="viz/VPS/gradients.png" alt="gradients">
                <figcaption>Using gradient samples to approximate local active subspaces </figcaption>
              </figure>
              <figure class="flex-figure-item">
                <img src="viz/VPS/POF_5000_herbie.png" alt="POF-darts">
                <figcaption>Adaptive sampling for probability of failure estimation [<a href="https://www.sciencedirect.com/science/article/abs/pii/S095183201630045X">paper</a>]</figcaption>
              </figure>
          </div>
          
          <hr>
          <!-- *********************************************************** -->
          
          <p> <b> Meshing and mesh tuning</b>: creating (or tuning) 2d/3d meshes with guaranteed quality properties.</p>
          
          <div class="flex-container">
          <figure class="flex-figure-item-400">
            <img src="viz/mesh/VC2.png" alt="allquad">
            <figcaption>VoroCrust: unclipped Voronoi mesh conforming to a high-quality surface mesh [<a href="https://dl.acm.org/doi/10.1145/3337680">paper</a>]</figcaption>
          </figure>
          
          <div class="flex-container">
              <img src="viz/mesh/chazelle_vc_cvt.jpg" alt="" width="250px" height="250px">
              <img src="viz/mesh/chazelle_vc_hex.jpg" alt="" width="250px" height="250px">
              <img src="viz/mesh/chazelle_vc_multi_mat.jpg" alt="" width="200px" height="200px">
          </div>
          
          <div class="flex-container">
              <figure>
                  <img src="viz/mesh/7grid_template.png" alt="" width="200px">
              </figure>
              
              <figure>
                  <img src="viz/mesh/quadtree_with_template.png" alt="" width="275px">
              </figure>
              <figure class="flex-figure-item-400">
                <img src="viz/mesh/cat.png" alt=""  width="500px">
                <figcaption>Robust All-Quad Meshing of Domains with Connected Regions, with angle and edge length guarantees [<a href="https://www.sciencedirect.com/science/article/pii/S1877705815032269">paper</a>]</figcaption>
              </figure>

          </div>
        
          </div>

          <!-- ****************************************************
          <div class="flex-container">
          <figure class="flex-figure-item">
            <img src="viz/mesh/7grid_template.png" alt="allquad">
            <figcaption>All-quad meshing algorithm [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4995448/">paper</a>]</figcaption>
          </figure>
          <figure class="flex-figure-item">
            <img src="viz/mesh/flower.png" alt="2d-allquad">
            <figcaption>2D: all quad meshing without cleanup [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4995448/">paper</a>]</figcaption>
          </figure>
          <figure class="flex-figure-item">
            <img src="viz/mesh/all-hex.png" alt="3d-allhex">
            <figcaption>3D: interface of an all-hexahedral mesh of a two-spheres model. [<a href="https://www.sciencedirect.com/science/article/pii/S1877705816333628">paper</a>]</figcaption>
          </figure>
          
          </div>
          ******* -->

          
          <hr>
          
          <!-- *********************************************************** -->
          
          <p> <b>From computational methods to scientific computing and engineering applications</b></p>
          
          Extending mesh tuning methods, e.g., for non-obtuse triangulation [<a href="https://dl.acm.org/doi/10.1111/cgf.12981">paper</a>], to accurately model fiber reinforced polymers for elastic and failure simulations.
          
          <div class="flex-container">
              
              <img src="viz/app/tuning.png" alt="object" width="275px">

              <figure class="flex-figure-item">
                  <img src="viz/app/micrograph.png" alt="object" width="150px" height="150px">
                  <img src="viz/app/peakstress.png" alt="object" width="150px" height="150px">
              </figure>

              <figure class="flex-figure-item-400">
                <img src="viz/app/fiber_plots2.png" alt="object">
                <figcaption>A cross-section of a
                    fiber micrograph and model at peak load and a simulated tensile responses
                    of different packings [<a href="https://dl.acm.org/doi/10.1111/cgf.12981">paper</a>]</figcaption>
              </figure>
          </div>
          
          Machine Learning for collision detection and motion planning.
          
          <div class="flex-container">
              
              <img src="viz/collision/motion.png" alt="object" width="200px">
                  <div class="flex-container">
                      <video class="video_teaser" autoplay loop muted playsinline> <source src="viz/collision/phase4.mp4" type="video/mp4">Your browser does not support the video tag.</video>
                      <video class="video_teaser" autoplay loop muted playsinline> <source src="viz/collision/phase3.mp4" type="video/mp4">Your browser does not support the video tag.</video>
                      <video class="video_teaser" autoplay loop muted playsinline> <source src="viz/collision/phase2.mp4" type="video/mp4">Your browser does not support the video tag.</video>
                      <video class="video_teaser" autoplay loop muted playsinline> <source src="viz/collision/phase1.mp4" type="video/mp4">Your browser does not support the video tag.</video>
                  </div>

          </div>


    <!-- *********************************************************** -->
    <!--HTML hr tag is used here-->
    <hr>
    <br>
    <br>
    <br>
    <center><footer>Copyright © 2025 Ahmad A. Rushdi. All Rights Reserved.</footer></center>
    
    
  </div>
</body>
</html>

